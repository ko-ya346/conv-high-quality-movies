{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04342a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T05:44:57.204927Z",
     "start_time": "2021-04-25T05:44:56.917105Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from src.config import CFG\n",
    "from src.dataset import Img_dataset, get_transform\n",
    "from src.model import Generator, Discriminator\n",
    "from src.utils import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d63744",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.IMG_DIR = '../input/4-3/images/high_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89164eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T05:47:11.441687Z",
     "start_time": "2021-04-25T05:47:11.314103Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = sorted(os.listdir(CFG.IMG_DIR))[2000]\n",
    "\n",
    "show_image(f'{CFG.IMG_DIR}/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6de1a",
   "metadata": {},
   "source": [
    "## データセットの中身を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa90b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataset\n",
    "paths = [f'{CFG.IMG_DIR}/{filename}' for path in os.listdir(CFG.IMG_DIR)]\n",
    "train_dataset = Img_dataset(paths, train_tran=get_transform(TRAIN=False),\n",
    "                            val_tran=get_transform(TRAIN=True))\n",
    "\n",
    "for i in range(1):\n",
    "    before = train_dataset[i][0].numpy().astype(int).transpose(1, 2, 0)\n",
    "    after = train_dataset[i][1].numpy().astype(int).transpose(1, 2, 0)\n",
    "    print(before.shape, after.shape)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(before)\n",
    "ax[1].imshow(after)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e46faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [3]\n",
    "\n",
    "for ss in l:\n",
    "    print(ss)\n",
    "    CFG.low_xsize = CFG.xsize // ss\n",
    "    CFG.low_ysize = CFG.ysize // ss\n",
    "    \n",
    "    # check dataset\n",
    "    paths = [f'{CFG.IMG_DIR}/{filename}' for path in os.listdir(CFG.IMG_DIR)]\n",
    "    train_dataset = Img_dataset(paths, train_tran=get_transform(TRAIN=False),\n",
    "                                val_tran=get_transform(TRAIN=True))\n",
    "\n",
    "    for i in range(1):\n",
    "        before = train_dataset[i][0].numpy().astype(int).transpose(1, 2, 0)\n",
    "        after = train_dataset[i][1].numpy().astype(int).transpose(1, 2, 0)\n",
    "        print(before.shape, after.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(50, 25))\n",
    "    ax[0].imshow(before)\n",
    "    ax[1].imshow(after)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b28245",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "gen = gen.to('cuda')\n",
    "\n",
    "summary(gen, (3, CFG.xsize, CFG.ysize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2735c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c36c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = 0\n",
    "\n",
    "for p in gen.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "        \n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ca447",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b495116",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55add4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in dis.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12242fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821eedc0",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True # autotunerが高速化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a97585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # check dataset\n",
    "    paths = [f'{CFG.IMG_DIR}/{path}' for path in os.listdir(CFG.IMG_DIR)]\n",
    "    train_dataset = Img_dataset(paths, train_tran=get_transform(TRAIN=False),\n",
    "                                val_tran=get_transform(TRAIN=True))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "\n",
    "    model_G, model_D = Generator(), Discriminator()\n",
    "    model_G, model_D = nn.DataParallel(model_G), nn.DataParallel(model_D)\n",
    "    model_G, model_D = model_G.to(device), model_D.to(device)\n",
    "    params_G = torch.optim.Adam(model_G.parameters(),\n",
    "                lr=0.0002, betas=(0.5, 0.999))\n",
    "    params_D = torch.optim.Adam(model_D.parameters(),\n",
    "                lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    if os.path.exists(CFG.trained_param):\n",
    "        states = torch.load(CFG.trained_param)\n",
    "        model_G.load_state_dict(states)\n",
    "        \n",
    "    \n",
    "    # 損失関数\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    mae_loss = nn.L1Loss()\n",
    "\n",
    "    # ロスを計算するためのラベル変数 (PatchGAN)\n",
    "    # aspect ratio 4:3\n",
    "    ones = torch.ones(CFG.xsize, 1, 22, 30).to(device)\n",
    "    zeros = torch.zeros(CFG.ysize, 1, 22, 30).to(device)\n",
    "\n",
    "    # エラー推移\n",
    "    result = {}\n",
    "    result[\"log_loss_G_sum\"] = []\n",
    "    result[\"log_loss_G_bce\"] = []\n",
    "    result[\"log_loss_G_mae\"] = []\n",
    "    result[\"log_loss_D\"] = []\n",
    "\n",
    "    for i in tqdm(range(200)):\n",
    "        print(f'epoch: {i+1}')\n",
    "        log_loss_G_sum, log_loss_G_bce, log_loss_G_mae, log_loss_D = [], [], [], []\n",
    "\n",
    "        for num, (high_image, low_image) in enumerate(train_loader):\n",
    "            batch_len = len(high_image)\n",
    "            high_image /= 255\n",
    "            high_image, low_image = high_image.to(device), low_image.to(device)\n",
    "\n",
    "            # Gの訓練\n",
    "            # 偽のカラー画像を作成\n",
    "            fake_color = model_G(low_image)\n",
    "\n",
    "            # 偽画像を一時保存\n",
    "            fake_color_tensor = fake_color.detach()\n",
    "\n",
    "            # 偽画像を本物と騙せるようにロスを計算\n",
    "            LAMBD = 100.0 # BCEとMAEの係数\n",
    "            out = model_D(torch.cat([fake_color, low_image], dim=1))\n",
    "            loss_G_bce = bce_loss(out, ones[:batch_len])\n",
    "            loss_G_mae = LAMBD * mae_loss(fake_color, high_image)\n",
    "            loss_G_sum = loss_G_bce + loss_G_mae\n",
    "            del fake_color\n",
    "\n",
    "            log_loss_G_bce.append(loss_G_bce.item())\n",
    "            log_loss_G_mae.append(loss_G_mae.item())\n",
    "            log_loss_G_sum.append(loss_G_sum.item())\n",
    "\n",
    "            # 微分計算・重み更新\n",
    "            params_D.zero_grad()\n",
    "            params_G.zero_grad()\n",
    "            loss_G_sum.backward()\n",
    "            params_G.step()\n",
    "\n",
    "            # Discriminatoの訓練\n",
    "            # 本物のカラー画像を本物と識別できるようにロスを計算\n",
    "            real_out = model_D(torch.cat([high_image, low_image], dim=1))\n",
    "            loss_D_real = bce_loss(real_out, ones[:batch_len])\n",
    "\n",
    "            # 偽の画像の偽と識別できるようにロスを計算\n",
    "            fake_out = model_D(torch.cat([fake_color_tensor, low_image], dim=1))\n",
    "            loss_D_fake = bce_loss(fake_out, zeros[:batch_len])\n",
    "\n",
    "            # 実画像と偽画像のロスを合計\n",
    "            loss_D = loss_D_real + loss_D_fake\n",
    "            log_loss_D.append(loss_D.item())\n",
    "\n",
    "            # 微分計算・重み更新\n",
    "            params_D.zero_grad()\n",
    "            params_G.zero_grad()\n",
    "            loss_D.backward()\n",
    "            params_D.step()\n",
    "            \n",
    "            \n",
    "\n",
    "        result[\"log_loss_G_sum\"].append(statistics.mean(log_loss_G_sum))\n",
    "        result[\"log_loss_G_bce\"].append(statistics.mean(log_loss_G_bce))\n",
    "        result[\"log_loss_G_mae\"].append(statistics.mean(log_loss_G_mae))\n",
    "        result[\"log_loss_D\"].append(statistics.mean(log_loss_D))\n",
    "        print(f\"log_loss_G_sum = {result['log_loss_G_sum'][-1]} \" +\n",
    "              f\"({result['log_loss_G_bce'][-1]}, {result['log_loss_G_mae'][-1]}) \" )\n",
    "        print(f\"log_loss_D = {result['log_loss_D'][-1]}\")\n",
    "\n",
    "        # 画像を保存\n",
    "        if not os.path.exists(CFG.OUTPUT_IMG):\n",
    "            os.mkdir(CFG.OUTPUT_IMG)\n",
    "        # 生成画像を保存\n",
    "        torchvision.utils.save_image(conv_scale(fake_color_tensor[:min(batch_len, 100)]),\n",
    "                                f\"{CFG.OUTPUT_IMG}/fake_epoch_{i:03}.png\",\n",
    "                                    )\n",
    "        torchvision.utils.save_image(conv_scale(high_image[:min(batch_len, 100)]),\n",
    "                                f\"{CFG.OUTPUT_IMG}/real_epoch_{i:03}.png\",\n",
    "                                    )\n",
    "\n",
    "        # モデルの保存\n",
    "        if not os.path.exists(CFG.OUTPUT_MODEL):\n",
    "            os.mkdir(CFG.OUTPUT_MODEL)\n",
    "        if i % 10 == 0 or i == 199:\n",
    "            torch.save(model_G.state_dict(), f\"{CFG.OUTPUT_MODEL}/gen_{i:03}.pytorch\")                        \n",
    "            torch.save(model_D.state_dict(), f\"{CFG.OUTPUT_MODEL}/dis_{i:03}.pytorch\")                        \n",
    "\n",
    "#     # ログの保存\n",
    "#     with open(\"stl_color/logs.pkl\", \"wb\") as fp:\n",
    "#         pickle.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50801ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
