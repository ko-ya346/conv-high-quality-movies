{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04342a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T05:44:57.204927Z",
     "start_time": "2021-04-25T05:44:56.917105Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from utils.dataset import Img_dataset, get_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4ff8f",
   "metadata": {},
   "source": [
    "# load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ace98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T05:45:00.831150Z",
     "start_time": "2021-04-25T05:45:00.829188Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_DIR = '../input/images/high_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    print(img.shape)    \n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89164eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T05:47:11.441687Z",
     "start_time": "2021-04-25T05:47:11.314103Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = sorted(os.listdir(IMG_DIR))[2000]\n",
    "\n",
    "show_image(IMG_DIR+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ed26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    shrink_scale = 16\n",
    "    xsize = 720\n",
    "    ysize = 960\n",
    "    low_xsize = xsize // shrink_scale\n",
    "    low_ysize = ysize // shrink_scale\n",
    "    batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1da88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img_dataset(Dataset):\n",
    "    def __init__(self, paths, train_tran, val_tran):\n",
    "        super().__init__()\n",
    "        self.paths = paths\n",
    "        self.train_tran = train_tran\n",
    "        self.val_tran = val_tran\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.paths[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "        return self.train_tran(image=image)['image'], self.val_tran(image=image)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(*, TRAIN=False):\n",
    "    if TRAIN:\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.low_xsize, CFG.low_ysize),\n",
    "            A.Resize(CFG.xsize, CFG.ysize, interpolation=Image.NEAREST),\n",
    "            ToTensorV2()\n",
    "            \n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6de1a",
   "metadata": {},
   "source": [
    "## データセットの中身を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa90b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataset\n",
    "paths = [IMG_DIR+path for path in os.listdir(IMG_DIR)]\n",
    "train_dataset = Img_dataset(paths, train_tran=get_transform(TRAIN=False),\n",
    "                            val_tran=get_transform(TRAIN=True))\n",
    "\n",
    "for i in range(1):\n",
    "    before = train_dataset[i][0].numpy().astype(int).transpose(1, 2, 0)\n",
    "    after = train_dataset[i][1].numpy().astype(int).transpose(1, 2, 0)\n",
    "    \n",
    "    plt.imshow(before)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.imshow(after)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc954dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821eedc0",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ff39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc1 = self.conv_bn_relu(1, 32, kernel_size=5) # 32x96x96\n",
    "        self.enc2 = self.conv_bn_relu(32, 64, kernel_size=3, pool_kernel=4)  # 64x24x24\n",
    "        self.enc3 = self.conv_bn_relu(64, 128, kernel_size=3, pool_kernel=2)  # 128x12x12\n",
    "        self.enc4 = self.conv_bn_relu(128, 256, kernel_size=3, pool_kernel=2)  # 256x6x6\n",
    "        \n",
    "        self.dec1 = self.conv_bn_relu(256, 128, kernel_size=3, pool_kernel=-2)  # 128x12x12\n",
    "        self.dec2 = self.conv_bn_relu(128 + 128, 64, kernel_size=3, pool_kernel=-2)  # 64x24x24\n",
    "        self.dec3 = self.conv_bn_relu(64 + 64, 32, kernel_size=3, pool_kernel=-4)  # 32x96x96\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.Conv2d(32 + 32, 3, kernel_size=5, padding=2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def conv_bn_relu(self, in_ch, out_ch, kernel_size=3, pool_kernel=None):\n",
    "        layers = []\n",
    "        if pool_kernel is not None:\n",
    "            if pool_kernel > 0:\n",
    "                layers.append(nn.AvgPool2d(pool_kernel))\n",
    "            elif pool_kernel < 0:\n",
    "                layers.append(nn.UpsamplingNearest2d(scale_factor=-pool_kernel))\n",
    "        layers.append(nn.Conv2d(in_ch, out_ch, kernel_size, padding=(kernel_size - 1) // 2))\n",
    "        layers.append(nn.BatchNorm2d(out_ch))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(x1)\n",
    "        x3 = self.enc3(x2)\n",
    "        x4 = self.enc4(x3)\n",
    "        out = self.dec1(x4)\n",
    "        out = self.dec2(torch.cat([out, x3], dim=1))\n",
    "        out = self.dec3(torch.cat([out, x2], dim=1))\n",
    "        out = self.dec4(torch.cat([out, x1], dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17731d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = self.conv_bn_relu(4, 16, kernel_size=5, reps=1) # fake/true color + gray\n",
    "        self.conv2 = self.conv_bn_relu(16, 32, pool_kernel=4)\n",
    "        self.conv3 = self.conv_bn_relu(32, 64, pool_kernel=2)\n",
    "        self.conv4 = self.conv_bn_relu(64, 128, pool_kernel=2)\n",
    "        self.conv5 = self.conv_bn_relu(128, 256, pool_kernel=2)\n",
    "        self.out_patch = nn.Conv2d(256, 1, kernel_size=1) #1x3x3\n",
    "\n",
    "    def conv_bn_relu(self, in_ch, out_ch, kernel_size=3, pool_kernel=None, reps=2):\n",
    "        layers = []\n",
    "        for i in range(reps):\n",
    "            if i == 0 and pool_kernel is not None:\n",
    "                layers.append(nn.AvgPool2d(pool_kernel))\n",
    "            layers.append(nn.Conv2d(in_ch if i == 0 else out_ch,\n",
    "                                    out_ch, kernel_size, padding=(kernel_size - 1) // 2))\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv5(self.conv4(self.conv3(self.conv2(self.conv1(x)))))\n",
    "        return self.out_patch(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f1964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
